name: Update YieldMax Data

on:
  schedule:
    # 매일 오전 12:05 KST (15:05 UTC) 실행
    - cron: '5 15 * * *'
  workflow_dispatch:
    # 수동 실행 가능
    inputs:
      force_update:
        description: 'Force update even if cache is valid'
        required: false
        default: false
        type: boolean

jobs:
  update-data:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      issues: write
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.21'
        
    - name: Cache Go modules
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/go-build
          ~/go/pkg/mod
        key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
        restore-keys: |
          ${{ runner.os }}-go-
          
    - name: Install dependencies
      run: go mod download
      
    - name: Create data directory
      run: mkdir -p docs
      
    - name: Run schedule crawler
      env:
        ALPHA_VANTAGE_API_KEY: ${{ secrets.ALPHA_VANTAGE_API_KEY }}
        FMP_API_KEY: ${{ secrets.FMP_API_KEY }}
        FORCE_UPDATE: ${{ github.event.inputs.force_update }}
      run: |
        echo "🚀 Starting DivMinder schedule crawler..."
        go run cmd/crawler/main.go
        echo "✅ Schedule crawler completed successfully"
        
    - name: Run dividend history scraper
      run: |
        echo "📊 Starting dividend history scraper..."
        go run cmd/scrape_dividends_cached/main.go
        echo "✅ Dividend history scraper completed successfully"
        
    - name: Check for data changes
      id: check_changes
      run: |
        if git diff --quiet docs/; then
          echo "changes=false" >> $GITHUB_OUTPUT
          echo "📊 No data changes detected"
        else
          echo "changes=true" >> $GITHUB_OUTPUT
          echo "📈 Data changes detected"
          git diff --stat docs/
        fi
        
    - name: Generate commit message
      if: steps.check_changes.outputs.changes == 'true'
      id: commit_message
      run: |
        TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S KST')
        ETF_COUNT=$(jq length docs/etfs.json 2>/dev/null || echo "0")
        SCHEDULE_COUNT=$(jq '.upcoming | length' docs/schedule_v3.json 2>/dev/null || echo "0")
        
        MESSAGE="🔄 Auto-update YieldMax data - $TIMESTAMP

        📊 Data Summary:
        - ETFs: $ETF_COUNT
        - Dividend Events: $SCHEDULE_COUNT
        - Updated Files: $(git diff --name-only docs/ | wc -l)
        
        🤖 Automated update via GitHub Actions"
        
        echo "message<<EOF" >> $GITHUB_OUTPUT
        echo "$MESSAGE" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
        
    - name: Commit and push changes
      if: steps.check_changes.outputs.changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add docs/
        git commit -m "${{ steps.commit_message.outputs.message }}"
        git push
        
    - name: Create success summary
      if: success()
      run: |
        echo "## ✅ DivMinder Data Update Successful" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Timestamp:** $(date '+%Y-%m-%d %H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "docs/api_summary_v3.json" ]; then
          echo "### 📊 Data Statistics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **ETFs:** $(jq -r '.data.totalETFs // "N/A"' docs/api_summary_v3.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **Data Sources:** $(jq -r '.data.dataSources | join(", ") // "N/A"' docs/api_summary_v3.json)" >> $GITHUB_STEP_SUMMARY
          echo "- **Version:** $(jq -r '.data.version // "N/A"' docs/api_summary_v3.json)" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📁 Updated Files" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        ls -la docs/ | tail -n +2 | while read line; do
          echo "- $line" >> $GITHUB_STEP_SUMMARY
        done
        
    - name: Create failure issue
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const title = `🚨 DivMinder Crawler Failed - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## 🚨 Crawler Execution Failed
          
          **Timestamp:** ${new Date().toLocaleString('ko-KR', {timeZone: 'Asia/Seoul'})} KST
          **Workflow:** ${context.workflow}
          **Run ID:** ${context.runId}
          **Run URL:** ${context.payload.repository.html_url}/actions/runs/${context.runId}
          
          ### 🔍 Possible Causes
          - API rate limits exceeded
          - Website structure changes
          - Network connectivity issues
          - Invalid API keys
          
          ### 🛠️ Next Steps
          1. Check the workflow logs for detailed error messages
          2. Verify API keys are valid and not expired
          3. Check if YieldMax website structure has changed
          4. Consider running the crawler manually to debug
          
          ### 📊 Last Successful Data
          Check the \`docs/\` directory for the most recent successful update.
          
          ---
          *This issue was automatically created by GitHub Actions*
          `;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: body,
            labels: ['bug', 'automated', 'crawler-failure']
          });

  # 데이터 품질 검사 작업
  quality-check:
    runs-on: ubuntu-latest
    needs: update-data
    if: always() && needs.update-data.result == 'success'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        ref: main  # 최신 커밋 사용
        
    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.21'
        
    - name: Install dependencies
      run: go mod download
      
    - name: Run data quality checks
      run: |
        echo "🔍 Running data quality checks..."
        
        # JSON 파일 유효성 검사
        for file in docs/*.json; do
          if [ -f "$file" ]; then
            echo "Validating $file..."
            if ! jq empty "$file" 2>/dev/null; then
              echo "❌ Invalid JSON: $file"
              exit 1
            else
              echo "✅ Valid JSON: $file"
            fi
          fi
        done
        
        # 필수 파일 존재 확인
        required_files=("docs/etfs.json" "docs/schedule_v3.json" "docs/api_summary_v3.json")
        for file in "${required_files[@]}"; do
          if [ ! -f "$file" ]; then
            echo "❌ Missing required file: $file"
            exit 1
          else
            echo "✅ Found required file: $file"
          fi
        done
        
        # 데이터 최소 요구사항 검사
        etf_count=$(jq length docs/etfs.json)
        if [ "$etf_count" -lt 50 ]; then
          echo "❌ ETF count too low: $etf_count (expected: >50)"
          exit 1
        else
          echo "✅ ETF count acceptable: $etf_count"
        fi
        
        echo "🎉 All data quality checks passed!"
        
    - name: Generate quality report
      run: |
        echo "## 📊 Data Quality Report" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Generated:** $(date '+%Y-%m-%d %H:%M:%S KST')" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # 파일 크기 정보
        echo "### 📁 File Sizes" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| File | Size |" >> $GITHUB_STEP_SUMMARY
        echo "|------|------|" >> $GITHUB_STEP_SUMMARY
        
        for file in docs/*.json; do
          if [ -f "$file" ]; then
            size=$(du -h "$file" | cut -f1)
            filename=$(basename "$file")
            echo "| $filename | $size |" >> $GITHUB_STEP_SUMMARY
          fi
        done
        
        # 데이터 통계
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📈 Data Statistics" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "docs/etfs.json" ]; then
          etf_count=$(jq length docs/etfs.json)
          echo "- **Total ETFs:** $etf_count" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "docs/schedule_v3.json" ]; then
          event_count=$(jq '.upcoming | length' docs/schedule_v3.json 2>/dev/null || echo "0")
          echo "- **Dividend Events:** $event_count" >> $GITHUB_STEP_SUMMARY
        fi
        
        dividend_files=$(ls docs/dividends_*.json 2>/dev/null | wc -l)
        echo "- **ETFs with History:** $dividend_files" >> $GITHUB_STEP_SUMMARY 